{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Anomaly Detection in Mackey-Glass Time Series with TCN-AE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/MarkusThill/bioma-tcn-ae/blob/main/src/main.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/MarkusThill/bioma-tcn-ae/blob/main/src/main.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More details to come...\n",
    "\n",
    "The following points should be considered:\n",
    "- When using Google CoLab, remember to activate GPU accelaration: \n",
    "  - Navigate to Editâ†’Notebook Settings\n",
    "  - select GPU from the Hardware Accelerator drop-down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running on Google CoLab!\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# First Check, if we are running in Google CoLab\n",
    "#\n",
    "IN_COLAB = 'google.colab' in str(get_ipython())\n",
    "if IN_COLAB:\n",
    "    print('Running on Google CoLab!')\n",
    "else:\n",
    "    print('Not running on Google CoLab!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Initially, install necessary packages and download the repository (required to access the data)\n",
    "#\n",
    "import os\n",
    "if IN_COLAB:\n",
    "    !pip3 install keras-tcn\n",
    "    if not os.path.exists('/content/bioma-tcn-ae/'):\n",
    "        print(\"Repo not cloned yet. Do it now!\")\n",
    "        !git clone https://github.com/MarkusThill/bioma-tcn-ae /content/bioma-tcn-ae/\n",
    "    else:\n",
    "        print(\"Repository already cloned!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# In Google CoLab: Change the working directory to bioma-tcn-ae/src\n",
    "#\n",
    "if IN_COLAB and os.getcwd() != \"/content/bioma-tcn-ae/src\":\n",
    "  # Print the current working directory\n",
    "  print(\"Old working directory: {0}\".format(os.getcwd()))\n",
    "\n",
    "  # Change the current working directory\n",
    "  os.chdir('/content/bioma-tcn-ae/src')\n",
    "\n",
    "  # Print the current working directory\n",
    "  print(\"New working directory: {0}\".format(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# If this cell throws an error, make sure that you activated GPU acceleration, as described above!\n",
    "#\n",
    "if IN_COLAB:\n",
    "    %tensorflow_version 2.x\n",
    "    import tensorflow as tf\n",
    "    device_name = tf.test.gpu_device_name()\n",
    "    if device_name != '/device:GPU:0':\n",
    "        raise SystemError('GPU device not found')\n",
    "    print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import time\n",
    "from utilities import select_gpus, plot_results # utilities.py: Contains a few miscellaneous functions \n",
    "from tcnae import TCNAE # tcnae.py: Specification of the TCN-AE model\n",
    "import data_swat # data.py: Allows to generate anomalous Mackey-Glass (MG) time series \n",
    "\n",
    "# If you have several GPUs, select one or more here (in a list)\n",
    "#select_gpus(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\giuli\\Documents\\bioma-tcn-ae\\src\\data_swat.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.label[data.label!=\"Normal\"]=1\n",
      "c:\\Users\\giuli\\Documents\\bioma-tcn-ae\\src\\data_swat.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.label[data.label==\"Normal\"]=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X.shape: (71968, 100, 44)\n"
     ]
    }
   ],
   "source": [
    "train_ts_id = 1 # [1-10]. Train the model on Mackey-Glass time series 1\n",
    "data_gen = data_swat.DataSwat()\n",
    "train_data = data_gen.build_data() # Returns a dictionary\n",
    "train_X = train_data[\"train_X\"] # We only need train_X (input = output) for the training process\n",
    "print(\"train_X.shape:\", train_X.shape) # A lot of training sequences of length 1050 and dimension 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None, 44)]        0         \n",
      "                                                                 \n",
      " tcn-enc (TCN)               (None, None, 20)          90700     \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, None, 8)           168       \n",
      "                                                                 \n",
      " average_pooling1d (AverageP  (None, None, 8)          0         \n",
      " ooling1D)                                                       \n",
      "                                                                 \n",
      " activation (Activation)     (None, None, 8)           0         \n",
      "                                                                 \n",
      " up_sampling1d (UpSampling1D  (None, None, 8)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " tcn-dec (TCN)               (None, None, 20)          75580     \n",
      "                                                                 \n",
      " dense (Dense)               (None, None, 44)          924       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 167,372\n",
      "Trainable params: 167,372\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "> Starting the Training...\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\giuli\\anaconda3\\envs\\tcn-ae\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\giuli\\anaconda3\\envs\\tcn-ae\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\giuli\\anaconda3\\envs\\tcn-ae\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\giuli\\anaconda3\\envs\\tcn-ae\\lib\\site-packages\\keras\\engine\\training.py\", line 994, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\giuli\\anaconda3\\envs\\tcn-ae\\lib\\site-packages\\keras\\engine\\training.py\", line 1052, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Users\\giuli\\anaconda3\\envs\\tcn-ae\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\giuli\\anaconda3\\envs\\tcn-ae\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\giuli\\anaconda3\\envs\\tcn-ae\\lib\\site-packages\\keras\\losses.py\", line 272, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\giuli\\anaconda3\\envs\\tcn-ae\\lib\\site-packages\\keras\\losses.py\", line 1935, in log_cosh\n        return backend.mean(_logcosh(y_pred - y_true), axis=-1)\n\n    ValueError: Dimensions must be equal, but are 84 and 100 for '{{node log_cosh/sub}} = Sub[T=DT_FLOAT](model/dense/BiasAdd, IteratorGetNext:1)' with input shapes: [16,84,44], [16,100,44].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\giuli\\Documents\\bioma-tcn-ae\\src\\main_swat.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/giuli/Documents/bioma-tcn-ae/src/main_swat.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m tcn_ae \u001b[39m=\u001b[39m TCNAE(ts_dimension\u001b[39m=\u001b[39mtrain_X\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m]) \u001b[39m# Use the parameters specified in the paper\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/giuli/Documents/bioma-tcn-ae/src/main_swat.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/giuli/Documents/bioma-tcn-ae/src/main_swat.ipynb#X13sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Train TCN-AE for 10 epochs. For a better accuracy \u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/giuli/Documents/bioma-tcn-ae/src/main_swat.ipynb#X13sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# on the test case, increase the epochs to epochs=40 \u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/giuli/Documents/bioma-tcn-ae/src/main_swat.ipynb#X13sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# The training takes about 3-4 minutes for 10 epochs, \u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/giuli/Documents/bioma-tcn-ae/src/main_swat.ipynb#X13sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# and 15 minutes for 40 epochs (on Google CoLab, with GPU enabled)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/giuli/Documents/bioma-tcn-ae/src/main_swat.ipynb#X13sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/giuli/Documents/bioma-tcn-ae/src/main_swat.ipynb#X13sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m tcn_ae\u001b[39m.\u001b[39;49mfit(train_X, train_X, batch_size\u001b[39m=\u001b[39;49m\u001b[39m16\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\giuli\\Documents\\bioma-tcn-ae\\src\\tcnae.py:154\u001b[0m, in \u001b[0;36mTCNAE.fit\u001b[1;34m(self, train_X, train_Y, batch_size, epochs, verbose)\u001b[0m\n\u001b[0;32m    152\u001b[0m     keras_verbose \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m\n\u001b[0;32m    153\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m--> 154\u001b[0m history \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mfit(train_X, train_Y, \n\u001b[0;32m    155\u001b[0m                     batch_size\u001b[39m=\u001b[39;49mbatch_size, \n\u001b[0;32m    156\u001b[0m                     epochs\u001b[39m=\u001b[39;49mepochs, \n\u001b[0;32m    157\u001b[0m                     validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.01\u001b[39;49m, \n\u001b[0;32m    158\u001b[0m                     shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    159\u001b[0m                     callbacks\u001b[39m=\u001b[39;49mmy_callbacks,\n\u001b[0;32m    160\u001b[0m                     verbose\u001b[39m=\u001b[39;49mkeras_verbose)\n\u001b[0;32m    161\u001b[0m \u001b[39mif\u001b[39;00m verbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    162\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m> Training Time :\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mround\u001b[39m(time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start), \u001b[39m\"\u001b[39m\u001b[39mseconds.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\giuli\\anaconda3\\envs\\tcn-ae\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file1d__d6pq.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\giuli\\anaconda3\\envs\\tcn-ae\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\giuli\\anaconda3\\envs\\tcn-ae\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\giuli\\anaconda3\\envs\\tcn-ae\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\giuli\\anaconda3\\envs\\tcn-ae\\lib\\site-packages\\keras\\engine\\training.py\", line 994, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\giuli\\anaconda3\\envs\\tcn-ae\\lib\\site-packages\\keras\\engine\\training.py\", line 1052, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Users\\giuli\\anaconda3\\envs\\tcn-ae\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\giuli\\anaconda3\\envs\\tcn-ae\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\giuli\\anaconda3\\envs\\tcn-ae\\lib\\site-packages\\keras\\losses.py\", line 272, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\giuli\\anaconda3\\envs\\tcn-ae\\lib\\site-packages\\keras\\losses.py\", line 1935, in log_cosh\n        return backend.mean(_logcosh(y_pred - y_true), axis=-1)\n\n    ValueError: Dimensions must be equal, but are 84 and 100 for '{{node log_cosh/sub}} = Sub[T=DT_FLOAT](model/dense/BiasAdd, IteratorGetNext:1)' with input shapes: [16,84,44], [16,100,44].\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "K.clear_session()\n",
    "# Build and compile the model\n",
    "#\n",
    "tcn_ae = TCNAE(ts_dimension=train_X.shape[2]) # Use the parameters specified in the paper\n",
    "\n",
    "#\n",
    "# Train TCN-AE for 10 epochs. For a better accuracy \n",
    "# on the test case, increase the epochs to epochs=40 \n",
    "# The training takes about 3-4 minutes for 10 epochs, \n",
    "# and 15 minutes for 40 epochs (on Google CoLab, with GPU enabled)\n",
    "#\n",
    "tcn_ae.fit(train_X, train_X, batch_size=16, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Test the model on another Mackey-Glass time series\n",
    "# Might take a few minutes...\n",
    "#\n",
    "start_time = time.time()\n",
    "test_ts_id = 3 # Test the model on Mackey-Glass time series 3\n",
    "test_data = data_gen.build_data(test_ts_id, verbose = 2) # Returns a dictionary\n",
    "\n",
    "#\n",
    "# Take the whole time series... Like the training data, the test data is standardized (zero mean and unit variance)\n",
    "#\n",
    "test_X = test_data[\"scaled_series\"].values[numpy.newaxis,:,:] # We need an extra dimension for the batch-dimension\n",
    "print(\"test_X.shape\", test_X.shape) # This is one long time series\n",
    "anomaly_score = tcn_ae.predict(test_X)\n",
    "print(\"> Time:\", round(time.time() - start_time), \"seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Make a plot of the anomaly-score and see how it matches the real anomaly windows\n",
    "# Vertical red bars show the actual anomalies.\n",
    "# Vertical yellow bars show regions which can be ignored (usually start and \n",
    "# end of a time series, which lead to transient behavior for some algorithms).\n",
    "# The blue curve is the anomaly score.\n",
    "# The red horizontal line indicates a simple threshold, which is the smallest possible value that would not produce a false positive\n",
    "#\n",
    "plot_results(test_data, anomaly_score, pl_range = None, plot_signal = False, plot_anomaly_score = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Take a look at the MG time series: zoom into the first anomaly\n",
    "#\n",
    "plot_results(test_data, anomaly_score, pl_range = (61000, 63000), plot_signal = True, plot_anomaly_score = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
